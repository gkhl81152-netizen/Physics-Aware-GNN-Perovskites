{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47252e5-8613-4593-a679-64d61dda1257",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_scatter\n",
    "import torch_geometric\n",
    "from torch_geometric import data as tg_data\n",
    "from torch_geometric.data import Dataset, DataLoader\n",
    "from torch_scatter import scatter,scatter_mean\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "from e3nn.nn import Gate\n",
    "from e3nn.nn.models.gate_points_2101 import Convolution, smooth_cutoff, tp_path_exists\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, namedtuple\n",
    "import pickle\n",
    "from ase import Atom,Atoms\n",
    "from ase.neighborlist import neighbor_list\n",
    "from mendeleev import element\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from pymatgen.core import Structure\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from typing import Dict\n",
    "import time\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops\n",
    "from torch_scatter import scatter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "datasets = ['g', 'y', 'r']\n",
    "palette = ['#43AA8B', '#F8961E', '#F94144']\n",
    "colors = dict(zip(datasets, palette))\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e72059-adfb-4012-be74-31800e05d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pymatgen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0051390a-fa4a-478e-a2d0-2d72f5f770ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('torch device:' , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0001f072-f0c8-4c80-b280-69ae762ada56",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb75380-0013-4d52-9e73-734c5bfc3140",
   "metadata": {},
   "source": [
    "数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d71370fa-bbe6-4952-a04f-a5d5e96fd5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(file_name):\n",
    "    match = re.search(r'mp-(\\d+)', file_name)\n",
    "    return int(match.group(1)) if match else float('inf')  # 返回匹配到的数字，未匹配的文件排在最后\n",
    "\n",
    "# 设置CIF文件夹路径\n",
    "cif_folder = '../train_set'\n",
    "\n",
    "# 获取所有CIF文件\n",
    "cif_files = [f for f in os.listdir(cif_folder) if f.endswith('.cif')]\n",
    "\n",
    "# 按照文件名中的数字进行升序排序\n",
    "cif_files.sort(key=lambda x: extract_number(os.path.basename(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e337c28a-a792-42c0-aed3-72d5957fce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = pd.read_excel('../train_set/train_materials_info.xlsx')\n",
    "\n",
    "df_info['mp_num'] = df_info['Material ID'].apply(lambda x: int(re.search(r'\\d+', str(x)).group()))\n",
    "# 根据提取的数字部分进行排序\n",
    "df_info_sorted = df_info.sort_values(by='mp_num', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "665e11af-b8fc-4d65-b3d8-0f50183846c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = df_info_sorted.iloc[:, -4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85978b1b-fe22-463f-92e8-be5661c73164",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoding for atomic types and data standardization complete.\n"
     ]
    }
   ],
   "source": [
    "# 定义元素属性的命名元组\n",
    "ElementProperties = namedtuple('ElementProperties', ['mass', 'dipole', 'radius', 'ionization_energy', 'electronegativity'])\n",
    "\n",
    "# 文件路径定义\n",
    "DATA_FILE = \"./element_data_v2.pkl\"\n",
    "\n",
    "# 加载或初始化元素数据\n",
    "def load_or_initialize_data(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        return load_data(file_path)\n",
    "    else:\n",
    "        return initialize_element_data(file_path)\n",
    "\n",
    "# 初始化元素数据\n",
    "def initialize_element_data(file_path):\n",
    "    type_mapping = {}\n",
    "    element_attributes = defaultdict(list)\n",
    "\n",
    "    # 获取所有元素的物理化学属性\n",
    "    for atomic_number in tqdm(range(1, 119)):  # 遍历元素周期表\n",
    "        element = Atom(atomic_number)  # 获取元素对象\n",
    "        element_symbol = element.symbol\n",
    "        type_mapping[element_symbol] = atomic_number - 1  # 原子类型映射\n",
    "\n",
    "        # 获取每个元素的物理化学属性\n",
    "        properties = extract_element_properties(element_symbol)\n",
    "\n",
    "        # 存储这些属性到字典\n",
    "        element_attributes['mass'].append(properties.mass)\n",
    "        element_attributes['dipole'].append(properties.dipole)\n",
    "        element_attributes['radius'].append(properties.radius)\n",
    "        element_attributes['ionization_energy'].append(properties.ionization_energy)\n",
    "        element_attributes['electronegativity'].append(properties.electronegativity)\n",
    "\n",
    "    # 数据标准化处理（对数值数据）\n",
    "    element_attributes = standardize_data(element_attributes)\n",
    "\n",
    "    # 保存初始化的数据\n",
    "    save_data(file_path, type_mapping, element_attributes)\n",
    "    return {\"type_mapping\": type_mapping, **element_attributes}\n",
    "\n",
    "# 提取元素的物理化学属性\n",
    "def extract_element_properties(symbol):\n",
    "    # 获取元素的物理化学属性，部分使用默认值填充\n",
    "    mass = element(symbol).mass\n",
    "    dipole = element(symbol).dipole_polarizability or 67.0\n",
    "    radius = element(symbol).covalent_radius_pyykko\n",
    "    ionization_energy = element(symbol).ionenergies.get(1, 7.5)\n",
    "    electronegativity = element(symbol).electronegativity(scale=\"pauling\") or 2.5\n",
    "\n",
    "    return ElementProperties(mass, dipole, radius, ionization_energy, electronegativity)\n",
    "\n",
    "# 加载已保存的数据\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# 保存数据到文件\n",
    "def save_data(file_path, type_mapping, element_attributes):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump({\"type_mapping\": type_mapping, **element_attributes}, f)\n",
    "\n",
    "# 标准化数值数据\n",
    "def standardize_data(element_attributes):\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # 对数值特征进行标准化\n",
    "    standardized_data = {}\n",
    "    for attribute, values in element_attributes.items():\n",
    "        if attribute in [\"mass\", \"dipole\", \"radius\", \"ionization_energy\", \"electronegativity\"]:\n",
    "            standardized_data[attribute] = scaler.fit_transform(torch.tensor(values, dtype=torch.float32).view(-1, 1)).squeeze().tolist()\n",
    "        else:\n",
    "            standardized_data[attribute] = values\n",
    "\n",
    "    return standardized_data\n",
    "\n",
    "# 加载元素数据\n",
    "data = load_or_initialize_data(DATA_FILE)\n",
    "\n",
    "type_mapping = data[\"type_mapping\"]\n",
    "mass_data = data[\"mass\"]\n",
    "dipole_data = data[\"dipole\"]\n",
    "radius_data = data[\"radius\"]\n",
    "ionization_energy_data = data[\"ionization_energy\"]\n",
    "electronegativity_data = data[\"electronegativity\"]\n",
    "\n",
    "# 创建原子类型的 one-hot 编码\n",
    "type_onehot = torch.eye(len(type_mapping))\n",
    "\n",
    "# 完成后的输出\n",
    "print(\"One-hot encoding for atomic types and data standardization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "275bf993-3681-49b7-807a-2d3bae9b88fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_weighted_angles(edge_src, edge_dst, edge_vec, edge_len, eps=1e-5):\n",
    "    \"\"\"\n",
    "    向量化计算共享同一中心节点的边的加权平均夹角：\n",
    "    对于每个边，计算与同一节点其它边（且目的节点不同）的夹角，并根据边长比加权平均。\n",
    "    \"\"\"\n",
    "    weighted_angles = torch.zeros(edge_src.size(0), device=edge_src.device, dtype=torch.float32)\n",
    "    unique_sources = torch.unique(edge_src)\n",
    "    for src in unique_sources:\n",
    "        # 找到同一源节点的所有边索引\n",
    "        idx = (edge_src == src).nonzero(as_tuple=False).squeeze()\n",
    "        if idx.dim() == 0:\n",
    "            idx = idx.unsqueeze(0)\n",
    "        # 若只有一条边，则没有可比较的角度\n",
    "        if idx.numel() <= 1:\n",
    "            continue\n",
    "        # 取出该组边的向量、边长和目的节点信息\n",
    "        E = edge_vec[idx]      # shape: (m, d)\n",
    "        dists = edge_len[idx]  # shape: (m,)\n",
    "        dests = edge_dst[idx]  # shape: (m,)\n",
    "        m = E.size(0)\n",
    "        # 利用矩阵运算计算所有边对的内积和模长外积\n",
    "        dot = E @ E.T           # shape: (m, m)\n",
    "        norms = dists\n",
    "        norms_outer = norms.unsqueeze(1) * norms.unsqueeze(0) + eps\n",
    "        cos = dot / norms_outer\n",
    "        cos = torch.clamp(cos, -1.0, 1.0)\n",
    "        angles = torch.acos(cos)  # shape: (m, m)\n",
    "        # 计算边长比：对于每对 (i, j) 用 dists[i] / dists[j]\n",
    "        ratios = dists.unsqueeze(1) / (dists.unsqueeze(0) + eps)\n",
    "        ratios = torch.clamp(ratios, 0.01, 10)\n",
    "        weighted = angles * ratios  # 加权角度矩阵\n",
    "        # 构造 mask：只保留目的节点不同的边对（自动排除自身比较，因为目的节点必然相同）\n",
    "        valid_mask = (dests.unsqueeze(1) != dests.unsqueeze(0))\n",
    "        # 对每条边计算有效加权角度的平均值\n",
    "        valid_weighted_sum = (weighted * valid_mask.float()).sum(dim=1)\n",
    "        valid_counts = valid_mask.float().sum(dim=1)\n",
    "        avg_angles = torch.where(valid_counts > 0, valid_weighted_sum / valid_counts, torch.zeros_like(valid_counts))\n",
    "        weighted_angles[idx] = avg_angles\n",
    "    return weighted_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a76e973e-3e27-4d5e-9099-9c321078e587",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_process(edge_len, start=0.0, stop=5.0, resolution=50, std=0.5):\n",
    "    means = torch.linspace(start, stop, resolution, device=edge_len.device) \n",
    "    edge_len = edge_len.unsqueeze(-1) \n",
    "    means = means.view(1, -1) \n",
    "    return torch.exp(-((edge_len - means) ** 2) / (2 * std ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cad28231-1faa-4e65-9742-113558a9f9ae",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_graph_data(positions, lattice, symbols, node_features, atomic_type_onehot,\n",
    "                      edge_index, edge_vec, edge_len, edge_shift, processed_edge_len, processed_edge_angle, target_value):\n",
    "    # 构造图数据对象\n",
    "    data = tg_data.Data()\n",
    "    data.pos = positions              # 原子位置（节点特征）\n",
    "    data.lattice = lattice            # 晶格信息\n",
    "    data.symbol = symbols             # 原子类型\n",
    "    data.x = node_features            # 节点特征\n",
    "    data.type = atomic_type_onehot    # 原子类型 one-hot 编码\n",
    "    data.edge_index = edge_index      # 边的索引\n",
    "    data.edge_vec = edge_vec          # 边的向量\n",
    "    data.edge_len = edge_len          # 边长\n",
    "    data.pre_edge_len = processed_edge_len  # 高斯处理后的边长\n",
    "    data.shift = edge_shift           # 邻居的周期性位移\n",
    "    data.edge_attr = processed_edge_angle     # 高斯处理后的角度\n",
    "    data.y = target_value             # 目标值\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bd87ed4-06a2-4035-8aed-0d65a1b35208",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def build_graph_data(entry, type_mapping, type_onehot, target_value, r_max=6.0,\n",
    "                     start=0.0, stop=1.0, resolution=50, sigma=1.0):\n",
    "    # 将输入结构转换为 ASE Atoms 对象\n",
    "    ase_atoms = Atoms(symbols=[site.species_string for site in entry.sites],\n",
    "                      positions=entry.cart_coords,\n",
    "                      cell=entry.lattice.matrix,\n",
    "                      pbc=True)\n",
    "    # 获取邻居边信息：边的源、目标和周期性位移\n",
    "    edge_src, edge_dst, edge_shift = neighbor_list(\"ijS\", ase_atoms, cutoff=r_max, self_interaction=True)\n",
    "    # 转为张量并放到指定设备上\n",
    "    edge_src = torch.tensor(edge_src, dtype=torch.long, device=device)\n",
    "    edge_dst = torch.tensor(edge_dst, dtype=torch.long, device=device)\n",
    "    edge_shift = torch.tensor(edge_shift, dtype=torch.float32, device=device)\n",
    "    \n",
    "    symbols = [site.species_string for site in entry.sites]\n",
    "    positions = torch.tensor(entry.cart_coords, dtype=torch.float32, device=device)\n",
    "    lattice = torch.tensor(entry.lattice.matrix, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    # 利用源节点索引构造与晶格信息对应的批次索引\n",
    "    edge_batch = positions.new_zeros(positions.shape[0], dtype=torch.long)[edge_src]\n",
    "    # 计算边向量：考虑周期性边界条件\n",
    "    edge_vec = (positions[edge_dst] - positions[edge_src] +\n",
    "                torch.einsum('ni,nij->nj', edge_shift, lattice[edge_batch]))\n",
    "    # 计算边长\n",
    "    edge_len = torch.norm(edge_vec, dim=1)\n",
    "    \n",
    "    # 利用向量化方法计算每条边的加权平均角度\n",
    "    edge_weight_angle = compute_weighted_angles(edge_src, edge_dst, edge_vec, edge_len)\n",
    "    \n",
    "    # 高斯处理边长和角度特征\n",
    "    processed_edge_len = gaussian_process(edge_len, start=start, stop=stop, resolution=resolution, std=sigma)\n",
    "    processed_edge_angle = gaussian_process(edge_weight_angle, start=start, stop=stop, resolution=resolution, std=sigma)\n",
    "    \n",
    "    # 构造符合 torch_geometric 要求的 edge_index（形状 [2, num_edges]）\n",
    "    edge_index = torch.stack([edge_src, edge_dst], dim=0)\n",
    "    \n",
    "    # 构造节点特征（假设 mass_data 等全局变量已定义）\n",
    "    mass = torch.tensor([mass_data[type_mapping[s]] for s in symbols], dtype=torch.float32, device=device)\n",
    "    dipole = torch.tensor([dipole_data[type_mapping[s]] for s in symbols], dtype=torch.float32, device=device)\n",
    "    radius = torch.tensor([radius_data[type_mapping[s]] for s in symbols], dtype=torch.float32, device=device)\n",
    "    ionization_energy = torch.tensor([ionization_energy_data[type_mapping[s]] for s in symbols], dtype=torch.float32, device=device)\n",
    "    electronegativity = torch.tensor([electronegativity_data[type_mapping[s]] for s in symbols], dtype=torch.float32, device=device)\n",
    "    node_features = torch.stack([mass, dipole, radius, ionization_energy, electronegativity], dim=1)\n",
    "    \n",
    "    atomic_type_onehot = type_onehot[[type_mapping[s] for s in symbols]].to(device)\n",
    "    \n",
    "    data = create_graph_data(positions, lattice, symbols, node_features, atomic_type_onehot,\n",
    "                             edge_index, edge_vec, edge_len, edge_shift,\n",
    "                             processed_edge_len, processed_edge_angle, target_value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26e0a676-1346-4381-bdd5-2d315890082d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process_and_save_batch_data(cif_folder, cif_files, type_mapping, type_onehot, target_column, \n",
    "                                r_max=6.0, start=0.0, stop=1.0, resolution=50, sigma=1.0, save_dir=\"processed_data\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    for i, cif_file in tqdm(enumerate(cif_files), desc=\"Processing CIF Files\", unit=\"file\"):\n",
    "        cif_path = os.path.join(cif_folder, cif_file)\n",
    "        structure = Structure.from_file(cif_path)\n",
    "        # 对于小结构，扩大超胞\n",
    "        if structure.num_sites <= 2:\n",
    "            structure = structure.make_supercell([[2, 0, 0], [0, 2, 0], [0, 0, 2]])\n",
    "        data = build_graph_data(entry=structure, type_mapping=type_mapping, type_onehot=type_onehot,\n",
    "                                target_value=target_column.iloc[i], r_max=r_max, start=start, stop=stop,\n",
    "                                resolution=resolution, sigma=sigma)\n",
    "        save_path = os.path.join(save_dir, f'{os.path.splitext(cif_file)[0]}.pt')\n",
    "        torch.save(data, save_path)\n",
    "        del data\n",
    "    print(f\"所有图数据已保存至 {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c13c5b5-5c25-4a39-8b00-c150ad8b8c83",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CIF Files: 0file [00:00, ?file/s]D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\pymatgen\\core\\structure.py:3087: EncodingWarning: We strongly encourage explicit `encoding`, and we would use UTF-8 by default as per PEP 686\n",
      "  with zopen(filename, mode=\"rt\", errors=\"replace\") as file:\n",
      "Processing CIF Files: 1file [00:00,  5.23file/s]D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\pymatgen\\core\\structure.py:3087: EncodingWarning: We strongly encourage explicit `encoding`, and we would use UTF-8 by default as per PEP 686\n",
      "  with zopen(filename, mode=\"rt\", errors=\"replace\") as file:\n",
      "Processing CIF Files: 1494file [00:25, 57.59file/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有图数据已保存至 ./processed_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run=True\n",
    "if run == True:\n",
    "    processed_data_folder = \"./processed_data\"\n",
    "    process_and_save_batch_data(cif_folder, cif_files, type_mapping, type_onehot, target_column, \n",
    "                                6.0, 0.0, 1.0, 50, 1.0, processed_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e45bb30-ce8c-4014-9fcb-aec43062e45f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, cif_folder, split='train', batch_size=32, graph_num=1):\n",
    "        self.cif_folder = cif_folder\n",
    "        self.split = split\n",
    "        self.batch_size = batch_size\n",
    "        self.graph_num = graph_num  # 加载第几张图数据\n",
    "\n",
    "        # 获取所有的 .pt 文件路径（每个材料对应一个图数据）\n",
    "        self.graph_files = [f for f in os.listdir(cif_folder) if f.endswith('.pt')]\n",
    "\n",
    "        # 每个图数据的划分\n",
    "        self.split_mapping = self.get_split_mapping()\n",
    "\n",
    "    def get_split_mapping(self):\n",
    "        split_mapping = {\n",
    "            'train': [],\n",
    "            'val': [],\n",
    "            'test': []\n",
    "        }\n",
    "\n",
    "        # 随机打乱图文件列表\n",
    "        graph_files = self.graph_files.copy()\n",
    "        random.shuffle(graph_files)\n",
    "\n",
    "        total_files = len(graph_files)\n",
    "        train_size = int(0.8 * total_files)\n",
    "        val_size = int(0.1 * total_files)\n",
    "\n",
    "        # 进行数据集划分\n",
    "        train_files = graph_files[:train_size]\n",
    "        val_files = graph_files[train_size:train_size + val_size]\n",
    "        test_files = graph_files[train_size + val_size:]\n",
    "\n",
    "        # 将文件映射到对应的分割集\n",
    "        split_mapping['train'].extend(train_files)\n",
    "        split_mapping['val'].extend(val_files)\n",
    "        split_mapping['test'].extend(test_files)\n",
    "\n",
    "        return split_mapping\n",
    "\n",
    "    def load_graph_data(self, graph_files, graph_num=1):\n",
    "        all_graphs = []\n",
    "\n",
    "        for graph_file in graph_files:\n",
    "            graph_path = os.path.join(self.cif_folder, graph_file)\n",
    "\n",
    "            if os.path.exists(graph_path):\n",
    "                graph = torch.load(graph_path)  # 加载图数据\n",
    "                all_graphs.append(graph)\n",
    "            else:\n",
    "                raise ValueError(f\"Graph data for {graph_file} is missing.\")\n",
    "\n",
    "        return all_graphs\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回当前数据集的大小\n",
    "        \"\"\"\n",
    "        return len(self.split_mapping[self.split])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        获取指定索引的图数据\n",
    "        \"\"\"\n",
    "        graph_file = self.split_mapping[self.split][idx]\n",
    "        \n",
    "        # 返回指定图数据\n",
    "        graphs = self.load_graph_data([graph_file], graph_num=self.graph_num)\n",
    "        \n",
    "        return graphs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073cdea5-4d62-4ad5-a42a-e381a689603b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_and_batch_data(cif_folder, batch_size=32, graph_num=1):\n",
    "    train_dataset = GraphDataset(cif_folder, split='train', graph_num=graph_num)\n",
    "    val_dataset = GraphDataset(cif_folder, split='val', graph_num=graph_num)\n",
    "    test_dataset = GraphDataset(cif_folder, split='test', graph_num=graph_num)\n",
    "\n",
    "    # 打印数据集大小\n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "    # 为每个数据集创建DataLoader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed408ee4-8d52-40ef-9456-f192d0e7aea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 1195\n",
      "Validation dataset size: 149\n",
      "Test dataset size: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "cif_folder1 = \"./processed_data\"\n",
    "batch_size = 8\n",
    "# 每批次的图数据数量\n",
    "train_loader, val_loader, test_loader = load_and_batch_data(cif_folder1, batch_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6e3b9ca-989a-47f2-9cda-74a1de43c22b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing graph data:   0%|                                                            | 0/1195 [00:00<?, ?material/s]C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23700\\1046099695.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph = torch.load(graph_path)  # 加载图数据\n",
      "Processing graph data: 100%|████████████████████████████████████████████████| 1195/1195 [00:02<00:00, 538.50material/s]\n",
      "Processing graph data: 100%|██████████████████████████████████████████████████| 149/149 [00:00<00:00, 588.61material/s]\n",
      "Processing graph data: 100%|██████████████████████████████████████████████████| 150/150 [00:00<00:00, 634.00material/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average number of neighbors (train/valid/test): 69.41714285714286 / 69.97558139534884 / 69.02138364779874\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_neighbors(graph_data):\n",
    "    n_neighbors = []\n",
    "    for data in tqdm(graph_data, desc=\"Processing graph data\", unit=\"material\"):   # 遍历图数据列表（每个列表对应一个材料）\n",
    "        N = data.pos.shape[0]  # 获取图中节点的数量\n",
    "        for i in range(N):\n",
    "            n_neighbors.append(len((data.edge_index[0] == i).nonzero()))  # 计算每个节点的邻居数\n",
    "    return np.array(n_neighbors)\n",
    "\n",
    "# 计算训练集、验证集和测试集的邻居数量\n",
    "train_neighbors = get_neighbors(train_loader.dataset)  # 获取训练集的邻居数\n",
    "valid_neighbors = get_neighbors(val_loader.dataset)  # 获取验证集的邻居数\n",
    "test_neighbors = get_neighbors(test_loader.dataset)  # 获取测试集的邻居数\n",
    "\n",
    "# 绘制邻居数量的直方图\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 4))\n",
    "b = 0.\n",
    "bins = 50\n",
    "for (d, c), n in zip(colors.items(), [train_neighbors, valid_neighbors, test_neighbors]):\n",
    "    color = [int(c.lstrip('#')[i:i+2], 16)/255. for i in (0, 2, 4)]\n",
    "    y, bins, _ = ax.hist(n, bins=bins, fc=color+[0.7], ec=color, bottom=b, label=d)\n",
    "    b += y\n",
    "ax.set_xlabel('Number of neighbors')\n",
    "ax.set_ylabel('Number of examples')\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "# 输出训练集、验证集和测试集的平均邻居数量\n",
    "print('average number of neighbors (train/valid/test):', train_neighbors.mean(), '/', valid_neighbors.mean(), '/', test_neighbors.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ac283a-8e1f-44ff-a3a7-940665b86918",
   "metadata": {},
   "source": [
    "模型设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55135372-007e-4504-8487-e1c183715a63",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class GatedGCNWithEdgeAttention(MessagePassing):\n",
    "    def __init__(self, dim_node=5, dim_edge=50, epsilon=1e-5, learnable_att_weight=True):\n",
    "        super().__init__(aggr='add')\n",
    "        \n",
    "        self.W_src = nn.Linear(dim_node, dim_node)\n",
    "        self.W_dst = nn.Linear(dim_node, dim_node)\n",
    "        self.W_e = nn.Linear(dim_edge, dim_edge)\n",
    "        self.W_a = nn.Linear(dim_edge, dim_edge)\n",
    "        self.W_u = nn.Linear(dim_node * 2 + dim_edge * 2, dim_edge)\n",
    "        self.W_v = nn.Linear(dim_node * 2 + dim_edge * 2, dim_edge)\n",
    "        \n",
    "        self.att_weight = nn.Parameter(torch.Tensor(1, dim_edge * 2)) if learnable_att_weight else None\n",
    "        self.att_bias = nn.Parameter(torch.Tensor(1))\n",
    "        self.edge_bias = nn.Parameter(torch.Tensor(1, dim_edge))\n",
    "        \n",
    "        self.sigma = nn.Sigmoid()\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.norm_x = nn.LayerNorm(dim_node)\n",
    "        self.norm_e = nn.LayerNorm(dim_edge)\n",
    "        self.eps = epsilon\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        if self.att_weight is not None:\n",
    "            nn.init.xavier_uniform_(self.att_weight)\n",
    "        if self.att_bias is not None:\n",
    "            nn.init.zeros_(self.att_bias)\n",
    "        if self.edge_bias is not None:\n",
    "            nn.init.zeros_(self.edge_bias)\n",
    "            \n",
    "        nn.init.xavier_uniform_(self.W_src.weight); self.W_src.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.W_dst.weight); self.W_dst.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.W_e.weight); self.W_e.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.W_a.weight); self.W_a.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.W_u.weight); self.W_u.bias.data.fill_(0)\n",
    "        nn.init.xavier_uniform_(self.W_v.weight); self.W_v.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_angle, pre_edge_len):\n",
    "        x = self.W_src(x)\n",
    "        return self.propagate(edge_index, x=x, pre_edge_len=pre_edge_len, edge_angle=edge_angle)\n",
    "\n",
    "    def message(self, x_j, edge_index, pre_edge_len, edge_angle):\n",
    "        edge_attention = self.compute_edge_attention(x_j, pre_edge_len, edge_index)\n",
    "        edge_attention = edge_attention + self.edge_bias.view(-1)\n",
    "        sigma_a = self.sigma(edge_angle)\n",
    "        a_sum = scatter(src=sigma_a, index=edge_index[0], dim=0 ,reduce='max')\n",
    "        a_gated = sigma_a / (a_sum[edge_index[0]] + self.eps)\n",
    "        return (edge_attention.view(-1, 1) * a_gated.view(-1, 1)) * self.W_dst(x_j)\n",
    "\n",
    "    def compute_edge_attention(self, x_j, pre_edge_len, edge_index):\n",
    "        edge_input = torch.cat([x_j, pre_edge_len], dim=-1)\n",
    "        grouped_attention = scatter(edge_input @ self.att_weight.t() + self.att_bias, edge_index[0], dim=0, reduce='max')\n",
    "        return F.softmax(grouped_attention, dim=1)  # 按每个节点归一化\n",
    "\n",
    "    def update(self, x, aggr_out, edge_index, pre_edge_len, edge_angle):\n",
    "        \n",
    "        x = self.norm_x(x)\n",
    "        pre_edge_len = self.norm_e(pre_edge_len)\n",
    "        edge_angle = self.norm_e(edge_angle)\n",
    "        \n",
    "        pre_edge_weights = self.act(self.W_e(pre_edge_len))\n",
    "        edge_angle_weights = self.act(self.W_a(edge_angle))\n",
    "        combined_edge_weights = self.norm_e(pre_edge_weights * edge_angle_weights)\n",
    "        \n",
    "        row, col = edge_index\n",
    "        weighted_edge_features = combined_edge_weights * aggr_out[row]\n",
    "        aggregated_edges = scatter(weighted_edge_features, index=col, dim=0 ,reduce='max')\n",
    "        updated_nodes = self.norm_x(aggregated_edges + x)\n",
    "        \n",
    "        z = torch.cat([x[edge_index[0]], x[edge_index[1]], edge_angle, pre_edge_len], dim=-1)\n",
    "        \n",
    "        edge_angle = edge_angle + self.act(self.norm_e(self.W_u(z)))\n",
    "        pre_edge_len = pre_edge_len + self.act(self.norm_e(self.W_v(z)))\n",
    "        \n",
    "        return self.act(updated_nodes), edge_angle, pre_edge_len\n",
    "\n",
    "    def propagate(self, edge_index, x, pre_edge_len, edge_angle):\n",
    "        row, col = edge_index\n",
    "        aggr_out = scatter(src=x[row], index=col, dim=0 ,reduce='max')\n",
    "        return self.update(x, aggr_out, edge_index, pre_edge_len, edge_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a271bfa7-3578-4569-9d0d-4a5ebc85661b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MGModel(nn.Module):\n",
    "    def __init__(self, dataset, hidden_dim=32, fc_num_layers=2, conv_num=1, dropout=0.1, sigma=1.0):\n",
    "        super().__init__()\n",
    "        self.dim_attr_node = dataset.x.shape[1]\n",
    "        self.dim_type_node = dataset.type.shape[1]\n",
    "        self.dim_edge = dataset.pre_edge_len.shape[1]\n",
    "        self.hidden_dim = hidden_dim\n",
    "        a = int(hidden_dim / 2)\n",
    "        self.node_attr_fc = self.build_mlp(self.dim_attr_node, a, fc_num_layers, dropout)\n",
    "        self.node_type_fc = self.build_mlp(self.dim_type_node, a, fc_num_layers, dropout)\n",
    "        self.edge_len_fc = self.build_mlp(self.dim_edge, hidden_dim, fc_num_layers, dropout)\n",
    "        self.edge_ang_fc = self.build_mlp(self.dim_edge, hidden_dim, fc_num_layers, dropout)\n",
    "        self.gated_layer = self.init_conv(conv_num, hidden_dim, 1e-5)\n",
    "        self.edge_out = nn.Linear(hidden_dim, 9)\n",
    "        self.angle_out = nn.Linear(hidden_dim, 9)\n",
    "        self.w_out = nn.Linear(18, 9)\n",
    "        self.node_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.edge_norm = nn.LayerNorm(9)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def build_mlp(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        layers = [nn.Linear(input_dim, hidden_dim), nn.LeakyReLU(), nn.Dropout(dropout), nn.BatchNorm1d(hidden_dim)]\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.extend([nn.Linear(hidden_dim, hidden_dim), nn.LeakyReLU(), nn.Dropout(dropout), nn.BatchNorm1d(hidden_dim)])\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.zeros_(layer.bias)\n",
    "\n",
    "    def init_conv(self, conv_num, hidden_dim, epsilon):\n",
    "        conv_num = max(1, conv_num)\n",
    "        conv_list = nn.ModuleList()\n",
    "        for _ in range(conv_num):\n",
    "            conv_list.append(GatedGCNWithEdgeAttention(hidden_dim, hidden_dim, epsilon))\n",
    "        return conv_list\n",
    "\n",
    "    def process_node_features(self, dataset):\n",
    "        # 直接对整个 tensor 进行运算，避免循环\n",
    "        node_features_a = self.node_attr_fc(dataset.x)\n",
    "        node_features_b = self.node_type_fc(dataset.type)\n",
    "        return torch.cat([node_features_a, node_features_b], dim=-1)\n",
    "\n",
    "    def process_edge_features(self, dataset):\n",
    "        edge_features_len = self.edge_len_fc(dataset.pre_edge_len)\n",
    "        edge_features_ang = self.edge_ang_fc(dataset.edge_attr)\n",
    "        return edge_features_len, edge_features_ang\n",
    "\n",
    "    def forward(self, dataset):\n",
    "        node_features = self.process_node_features(dataset)\n",
    "        edge_features_len, edge_features_ang = self.process_edge_features(dataset)\n",
    "        for conv_layer in self.gated_layer:\n",
    "            node_features, edge_features_ang, edge_features_len = conv_layer(\n",
    "                node_features, dataset.edge_index, edge_features_ang, edge_features_len\n",
    "            )\n",
    "        node_output = self.node_norm(node_features)\n",
    "        edge_output = self.edge_norm(self.edge_out(edge_features_len))\n",
    "        angle_output = self.angle_out(edge_features_ang)\n",
    "        weight_edge = self.w_out(torch.cat([edge_output, angle_output], dim=-1))\n",
    "        return node_output, weight_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b15ab6b0-a7b9-44bc-8567-c83d9d20e8f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class CustomCompose(nn.Module):\n",
    "    def __init__(self, first, second):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "\n",
    "    def forward(self, *input):\n",
    "        x = self.first(*input)\n",
    "        return self.second(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ea84be6-cebd-41c1-8242-4203ed041891",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, in_dim, em_dim, irreps_in, irreps_out, irreps_node_attr, layers, mul, lmax, max_radius,\n",
    "                 number_of_basis=10, radial_layers=1, radial_neurons=100, num_neighbors=1., num_nodes=1.,\n",
    "                 reduce_output=True):\n",
    "        super().__init__()\n",
    "        self.mul = mul\n",
    "        self.lmax = lmax\n",
    "        self.max_radius = max_radius\n",
    "        self.number_of_basis = number_of_basis\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.num_nodes = num_nodes\n",
    "        self.reduce_output = reduce_output\n",
    "\n",
    "        self.irreps_in = o3.Irreps(irreps_in) if irreps_in is not None else None\n",
    "        self.irreps_hidden = o3.Irreps([(self.mul, (l, p)) for l in range(lmax + 1) for p in [-1, 1]])\n",
    "        self.irreps_out = o3.Irreps(irreps_out)\n",
    "        self.irreps_node_attr = o3.Irreps(irreps_node_attr) if irreps_node_attr is not None else o3.Irreps(\"0e\")\n",
    "        self.irreps_edge_attr = o3.Irreps.spherical_harmonics(lmax)\n",
    "        self.input_has_node_in = (irreps_in is not None)\n",
    "        self.input_has_node_attr = (irreps_node_attr is not None)\n",
    "        self.em_r = nn.Linear(1, em_dim)\n",
    "        self.em_c = nn.Linear(in_dim, em_dim)\n",
    "        act = {1: torch.nn.functional.silu, -1: torch.nn.functional.leaky_relu}\n",
    "        act_gates = {1: torch.sigmoid, -1: torch.nn.functional.silu}\n",
    "        irreps = self.irreps_in if self.irreps_in is not None else o3.Irreps(\"0e\")\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(layers):\n",
    "            irreps_scalars = o3.Irreps([\n",
    "                (mul, ir) for mul, ir in self.irreps_hidden \n",
    "                if ir.l == 0 and tp_path_exists(irreps, self.irreps_edge_attr, ir)\n",
    "            ])\n",
    "            irreps_gated = o3.Irreps([\n",
    "                (mul, ir) for mul, ir in self.irreps_hidden \n",
    "                if ir.l > 0 and tp_path_exists(irreps, self.irreps_edge_attr, ir)\n",
    "            ])\n",
    "            irreps_gates = o3.Irreps([(mul, \"0e\") for mul, _ in irreps_gated])\n",
    "            \n",
    "            gate = Gate(\n",
    "                irreps_scalars, [act[ir.p] for _, ir in irreps_scalars],\n",
    "                irreps_gates, [torch.sigmoid for _ in irreps_gates],\n",
    "                irreps_gated\n",
    "            )\n",
    "            conv = Convolution(\n",
    "                irreps, self.irreps_node_attr, self.irreps_edge_attr, gate.irreps_in,\n",
    "                number_of_basis, radial_layers, radial_neurons, num_neighbors\n",
    "            )\n",
    "            irreps = gate.irreps_out\n",
    "            self.layers.append(CustomCompose(conv, gate))\n",
    "        self.layers.append(\n",
    "            Convolution(irreps, self.irreps_node_attr, self.irreps_edge_attr, self.irreps_out,\n",
    "                        number_of_basis, radial_layers, radial_neurons, num_neighbors)\n",
    "        )\n",
    "\n",
    "    def preprocess(self, data: dict):\n",
    "        batch = data.get('batch', data['pos'].new_zeros(data['pos'].shape[0]))\n",
    "        edge_index = data.edge_index\n",
    "        edge_src, edge_dst = edge_index[0], edge_index[1]\n",
    "        edge_vec = data['edge_vec']\n",
    "        return batch, edge_src, edge_dst, edge_vec\n",
    "\n",
    "    def forward(self, data: dict, node_output=None, weight_edge=None) -> torch.Tensor:\n",
    "        batch, edge_src, edge_dst, edge_vec = self.preprocess(data)\n",
    "        edge_length = edge_vec.norm(dim=1)\n",
    "        edge_length_embedded = soft_one_hot_linspace(\n",
    "            x=edge_length,\n",
    "            start=0.0,\n",
    "            end=self.max_radius,\n",
    "            number=self.number_of_basis,\n",
    "            basis='gaussian',\n",
    "            cutoff=False\n",
    "        ).mul(self.number_of_basis ** 0.5)\n",
    "        edge_attr = smooth_cutoff(edge_length / self.max_radius)[:, None] * weight_edge\n",
    "        # 直接使用 em_c 对整个 tensor 运算，避免列表解析\n",
    "        symbol = self.em_c(data.type)\n",
    "        node_features = node_output\n",
    "        for layer in self.layers:\n",
    "            node_features = layer(node_features, symbol, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "        if self.reduce_output:\n",
    "            return scatter(node_features, batch, dim=0).div(self.num_nodes ** 0.5)\n",
    "        else:\n",
    "            return scatter_mean(node_features, batch, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2cde522-3b08-4dae-a6de-12f12c66c8da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MGE3_Model(nn.Module):\n",
    "    def __init__(self, dataset, in_dim, em_dim, irreps_in, irreps_out, irreps_node_attr, layers, mul, lmax, max_radius,\n",
    "                 number_of_basis=10, radial_layers=1, radial_neurons=100, num_neighbors=1., num_nodes=1., dropout=0.1,\n",
    "                 fc_num_layers=2, conv_num=1, sigma=1.0, reduce_output=True):\n",
    "        super().__init__()\n",
    "        self.mg_model = MGModel(dataset, hidden_dim=32, fc_num_layers=fc_num_layers, conv_num=conv_num,\n",
    "                                dropout=dropout, sigma=sigma)\n",
    "        self.network = Network(in_dim, em_dim, irreps_in, irreps_out, irreps_node_attr, layers, mul, lmax,\n",
    "                               max_radius, number_of_basis, radial_layers, radial_neurons, num_neighbors,\n",
    "                               num_nodes, reduce_output)\n",
    "\n",
    "    def forward(self, data: dict) -> torch.Tensor:\n",
    "        node_output, weight_edge = self.mg_model(data)\n",
    "        final_node_output = self.network(data, node_output=node_output, weight_edge=weight_edge)\n",
    "        return final_node_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e362901-8434-4155-b9ec-64af922e0308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23700\\1046099695.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph = torch.load(graph_path)  # 加载图数据\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\gkhl\\Lib\\site-packages\\torch\\jit\\_check.py:178: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "in_dim = 118\n",
    "em_dim = 32\n",
    "out_dim = 1\n",
    "\n",
    "model = MGE3_Model(\n",
    "    dataset=next(iter(train_loader))[0],\n",
    "    in_dim=in_dim,\n",
    "    em_dim=em_dim,\n",
    "    irreps_in=f\"{em_dim}x0e\",\n",
    "    irreps_out=f\"{out_dim}x0e\",\n",
    "    irreps_node_attr=f\"{em_dim}x0e\",\n",
    "    layers=2,\n",
    "    mul=32,\n",
    "    lmax=2,\n",
    "    max_radius=6.0,\n",
    "    num_neighbors=train_neighbors.mean(),\n",
    "    dropout=0.5,\n",
    "    fc_num_layers=1,\n",
    "    conv_num=5,\n",
    "    sigma=1.0,\n",
    "    reduce_output=True\n",
    ")\n",
    "\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f08efbd-4b1c-40fd-aa2a-a80cff1f6a08",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23700\\1046099695.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph = torch.load(graph_path)  # 加载图数据\n"
     ]
    }
   ],
   "source": [
    "def compute_median_iqr(train_loader):\n",
    "    all_targets = []\n",
    "    for _, d in enumerate(train_loader):\n",
    "        # 过滤掉 NaN 值\n",
    "        all_targets.append(d.y[~np.isnan(d.y.numpy())].numpy())\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    # 计算目标值的中位数和IQR（四分位差）\n",
    "    median_y = np.median(all_targets)\n",
    "    iqr_y = np.percentile(all_targets, 75) - np.percentile(all_targets, 25)\n",
    "    \n",
    "    # 计算最小值\n",
    "    min_y = (np.min(all_targets)-median_y)/iqr_y\n",
    "\n",
    "    return median_y, iqr_y, min_y\n",
    "\n",
    "# 计算训练集的中位数、IQR和最小值\n",
    "median_y, iqr_y, min_y = compute_median_iqr(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87216586-4590-4f8f-b139-9e7eb6b21535",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.2124244119749994\n",
      "1.319799072143677\n"
     ]
    }
   ],
   "source": [
    "print(median_y)\n",
    "print(iqr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1b2f688-2968-4323-8c9b-d5e69b555c5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def robust_normalize(y, median_y, iqr_y,min_y):\n",
    "    normalized_y = (y - median_y) / iqr_y\n",
    "    return torch.tensor(normalized_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac3445b9-aa36-4258-8268-288d68379c9b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, dataloader_train, dataloader_valid, loss_fn, loss_fn_mae, run_name,\n",
    "          max_iter=101, scheduler=None, scheduler_exponential=None, device=\"cpu\"):\n",
    "    model.to(device)\n",
    "\n",
    "    checkpoint_generator = loglinspace(0.2, 5)\n",
    "    checkpoint = next(checkpoint_generator)\n",
    "    start_time = time.time()\n",
    "\n",
    "    try: model.load_state_dict(torch.load('./model/' + run_name + '.torch')['state'])\n",
    "    except:\n",
    "        results = {}\n",
    "        history = []\n",
    "        s0 = 0\n",
    "        print(\"b\")\n",
    "    else:\n",
    "        results = torch.load('./model/' + run_name + '.torch')\n",
    "        history = results['history']\n",
    "        s0 = history[-1]['step'] + 1\n",
    "        print(\"a\")\n",
    "    \n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        model.train()\n",
    "        loss_cumulative = 0.\n",
    "        loss_cumulative_mae = 0.\n",
    "        \n",
    "    \n",
    "    for step in range(max_iter):\n",
    "        model.train()\n",
    "        loss_cumulative = 0.\n",
    "        loss_cumulative_mae = 0.\n",
    "        \n",
    "        for j, d in tqdm(enumerate(dataloader_train), total=len(dataloader_train), bar_format=bar_format):\n",
    "            d.edge_index = torch.tensor(d.edge_index)\n",
    "            \n",
    "            d.to(device)\n",
    "            d.y = d.y.float()\n",
    "            d.y = robust_normalize(d.y, median_y, iqr_y, min_y)\n",
    "            output = model(d)\n",
    "            output = output.squeeze()\n",
    "            d.y = torch.nan_to_num(d.y, nan=0.0)\n",
    "            \n",
    "            loss = loss_fn(output, d.y).cpu()\n",
    "            loss_mae = loss_fn_mae(output, d.y).cpu()\n",
    "            loss_em = 1 * loss + 0 * loss_mae\n",
    "            loss_cumulative += loss.detach().item()\n",
    "            loss_cumulative_mae += loss_mae.detach().item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            torch.autograd.set_detect_anomaly(True)\n",
    "            loss_em.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        end_time = time.time()\n",
    "        wall = end_time - start_time\n",
    "\n",
    "        if step == checkpoint:\n",
    "            checkpoint = next(checkpoint_generator)\n",
    "            assert checkpoint > step\n",
    "\n",
    "            valid_avg_loss = evaluate(model, dataloader_valid, loss_fn, loss_fn_mae, device)\n",
    "            train_avg_loss = evaluate(model, dataloader_train, loss_fn, loss_fn_mae, device)\n",
    "\n",
    "            history.append({\n",
    "                'step': s0 + step,\n",
    "                'wall': wall,\n",
    "                'batch': {\n",
    "                    'loss': loss.item(),\n",
    "                    'mean_abs': loss_mae.item(),\n",
    "                },\n",
    "                'valid': {\n",
    "                    'loss': valid_avg_loss[0],\n",
    "                    'mean_abs': valid_avg_loss[1],\n",
    "                },\n",
    "                'train': {\n",
    "                    'loss': train_avg_loss[0],\n",
    "                    'mean_abs': train_avg_loss[1],\n",
    "                },\n",
    "            })\n",
    "\n",
    "            results = {\n",
    "                'history': history,\n",
    "                'state': model.state_dict()\n",
    "            }\n",
    "\n",
    "            print(f\"Iteration {step+1:4d}   \" +\n",
    "                  f\"train loss = {train_avg_loss[1]:8.4f}   \" +\n",
    "                  f\"train loss_2 = {train_avg_loss[0]:8.4f}   \" +\n",
    "                  f\"valid loss = {valid_avg_loss[1]:8.4f}   \" +\n",
    "                  f\"valid loss_2 = {valid_avg_loss[0]:8.4f}   \" +\n",
    "                  f\"elapsed time = {time.strftime('%H:%M:%S', time.gmtime(wall))}\")\n",
    "\n",
    "            output_dir = './model/'\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "            with open(f'./model/{run_name}.torch', 'wb') as f:\n",
    "                torch.save(results, f)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        if step >= warmup_steps and scheduler_exponential is not None:\n",
    "            scheduler_exponential.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b74d751-e527-4716-bcd3-e4a80988519e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_fn, loss_fn_mae, device):\n",
    "    model.eval()\n",
    "    loss_cumulative = 0.\n",
    "    loss_cumulative_mae = 0.\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for j, d in enumerate(dataloader):\n",
    "            d.edge_index = torch.tensor(d.edge_index)\n",
    "            d.to(device)\n",
    "            d.y = robust_normalize(d.y, median_y, iqr_y,min_y)\n",
    "            output = model(d)\n",
    "            output = output.squeeze()\n",
    "            d.y = d.y.float()\n",
    "            d.y = torch.nan_to_num(d.y, nan=0.0)\n",
    "            \n",
    "            loss = loss_fn(output, d.y).cpu()\n",
    "            loss_mae = loss_fn_mae(output, d.y).cpu()\n",
    "            loss_cumulative = loss_cumulative + loss.detach().item()\n",
    "            loss_cumulative_mae = loss_cumulative_mae + loss_mae.detach().item()\n",
    "    return loss_cumulative/len(dataloader), loss_cumulative_mae/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96cfbeeb-7ddb-4c9d-957e-d83213c59d5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def loglinspace(rate, step, end=None):\n",
    "    t = 0\n",
    "    while end is None or t <= end:\n",
    "        yield t\n",
    "        t = int(t + 1 + step*(1 - math.exp(-t*rate/step)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96169b1e-4deb-4b28-adf9-a1c8f969cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.05)\n",
    "\n",
    "warmup_steps = 5\n",
    "initial_lr = 1e-6\n",
    "max_lr = 5e-4\n",
    "def lr_lambda(step):\n",
    "    if step < warmup_steps:\n",
    "        return initial_lr + (max_lr - initial_lr) * step / warmup_steps\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "scheduler_warmup = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)\n",
    "scheduler_exponential = torch.optim.lr_scheduler.ExponentialLR(opt, gamma=0.6)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.HuberLoss(delta=0.3)\n",
    "loss_fn_mae = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb78ec42-4f14-4d53-9044-688b32329e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_format = '{l_bar}{bar:10}{r_bar}{bar:-10b}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030702c-7f05-4242-aead-0e9aeb9ad3c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23700\\128046451.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  try: model.load_state_dict(torch.load('./model/' + run_name + '.torch')['state'])\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23700\\128046451.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  results = torch.load('./model/' + run_name + '.torch')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]                                                                                C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23700\\1046099695.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph = torch.load(graph_path)  # 加载图数据\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23700\\128046451.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d.edge_index = torch.tensor(d.edge_index)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23700\\1336829745.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(normalized_y)\n",
      " 11%|█▏        | 17/150 [00:17<02:07,  1.05it/s]                                                                       "
     ]
    }
   ],
   "source": [
    "run_name = 'model_eps_' + \"03\"\n",
    "model.pool = True\n",
    "train(model, opt, train_loader, val_loader, loss_fn, loss_fn_mae, run_name,max_iter=99, scheduler=scheduler_warmup, \n",
    "      scheduler_exponential=scheduler_exponential,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd53cc-ab2c-4364-bc08-9af6020304af",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = torch.load('./model/' + run_name + '.torch', map_location=device)['history']\n",
    "steps = [d['step'] + 1 for d in history]\n",
    "loss_train = [d['train']['loss'] for d in history]\n",
    "\n",
    "loss_valid = [d['valid']['loss'] for d in history]\n",
    "\n",
    "np.savetxt(run_name+'_MSE_loss.txt', np.column_stack((steps, loss_train, loss_valid)), fmt='%.8f', delimiter='\\t')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "ax.plot(steps, loss_train, 'o-', label=\"Training\", color='C0')\n",
    "ax.plot(steps, loss_valid, 'o-', label=\"Validation\", color='C3')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "fig.savefig(run_name + '_loss.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b69e413-4a46-4ea5-a185-cbcbb35149dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./model/'+run_name + '.torch', map_location=device)['state'])\n",
    "model.pool = True\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceea725-b5bd-4586-a372-3ef62c8754f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_samples = sum(len(batch.y) for batch in test_loader)\n",
    "\n",
    "# 根据样本数初始化 DataFrame\n",
    "df = pd.DataFrame(index=range(total_samples), columns=['y_true', 'y_pred', 'mse'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    i0 = 0\n",
    "    for i, d in tqdm(enumerate(test_loader), total=len(test_loader), bar_format=bar_format):\n",
    "        d.edge_index = torch.tensor(d.edge_index)\n",
    "        d.to(device)\n",
    "        d.y = d.y.float()\n",
    "        d.y = torch.nan_to_num(d.y, nan=0.0)\n",
    "        d.y = robust_normalize(d.y, median_y, iqr_y,min_y)\n",
    "        output = model(d).squeeze()\n",
    "        loss = F.mse_loss(output, d.y, reduction='none').mean(dim=-1).cpu().numpy()\n",
    "        df.loc[i0:i0 + len(d.y) - 1, 'y_pred'] = output.cpu().numpy()\n",
    "        df.loc[i0:i0 + len(d.y) - 1, 'mse'] = loss\n",
    "        df.loc[i0:i0 + len(d.y) - 1, 'y_true'] = d.y.cpu().numpy()\n",
    "        i0 += len(d.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c2652-3895-41a1-9419-af83bade8ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算误差的绝对值\n",
    "df['error'] = abs(df['y_pred'] - df['y_true'])\n",
    "\n",
    "# 找到误差最大的索引\n",
    "max_error_index = df['error'].idxmax()\n",
    "\n",
    "# 删除误差最大的一行\n",
    "df = df.drop(index=max_error_index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f45d9-dd89-4e9a-bff9-bf3deb00bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df['y_true'].to_numpy() \n",
    "y_pre = df['y_pred'].to_numpy()\n",
    "\n",
    "y_pre =( y_pre)*  iqr_y + median_y\n",
    "y_test =( y_test) * iqr_y + median_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c1a04-648b-4d49-bd7a-65cbd966282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "print(\"mean_absolute_error:\",mean_absolute_error(y_test,y_pre))\n",
    "print(\"mean_squared_error:\",mean_squared_error(y_test,y_pre))\n",
    "print(\"rmse:\",sqrt(mean_squared_error(y_test,y_pre)))\n",
    "print(\"r2:\",r2_score(y_test,y_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae281f-ce38-448c-aa13-ffe77cb2a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(list(range(1, len(y_test) + 1)), y_test, label='True Values', marker='o')\n",
    "plt.plot(list(range(1, len(y_pre) + 1)), y_pre, label='Predicted Values', marker='x')\n",
    "plt.xlabel('Observation')\n",
    "plt.ylabel('energy')\n",
    "plt.xlim([1, len(y_test)])\n",
    "plt.legend()\n",
    "plt.title('True vs Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc70a9-9e12-4b4a-b4a2-93cf61dc0fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.to_numeric(y_test, errors='coerce')\n",
    "y_pre = pd.to_numeric(y_pre, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37a4a7-1f32-4125-86e5-0ec806223d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "errors = np.abs(np.array(y_test) - np.array(y_pre))\n",
    "colors = np.interp(errors, (errors.min(), errors.max()), (0, 1))  # 归一化到 [0, 1]\n",
    "\n",
    "colors_list = [(0.3, 0, 0.5), (1, 0.9, 0.6)]  # 深紫色到更浅的橘黄色\n",
    "cmap = LinearSegmentedColormap.from_list('purple_lightorange', colors_list)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "scatter = plt.scatter(y_test, y_pre, c=colors, cmap=cmap, edgecolor='none')\n",
    "\n",
    "# 添加参考线\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='darkblue', linestyle='--')\n",
    "\n",
    "# 设置标签和标题\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "\n",
    "# 去掉网格线\n",
    "plt.grid(False)\n",
    "\n",
    "# 显示颜色条，并设置标签\n",
    "cbar = plt.colorbar(scatter)\n",
    "\n",
    "# 标注 R²、MAE 和 RMSE\n",
    "\n",
    "r2 = r2_score(y_test,y_pre)\n",
    "mae = mean_absolute_error(y_test,y_pre)\n",
    "rmse = sqrt(mean_squared_error(y_test,y_pre))  \n",
    "\n",
    "plt.text(0.95, 0.05, f'$R^2$ = {r2:.5f}\\nMAE = {mae:.5f}\\nRMSE = {rmse:.5f}', \n",
    "         horizontalalignment='right', verticalalignment='bottom', \n",
    "         transform=plt.gca().transAxes, fontsize=12, \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='black'))\n",
    "\n",
    "# 显示图形\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e9c78-bfee-4e3f-b88c-a95b5e722f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# 假设 y_test, y_pre 已经定义\n",
    "errors = np.abs(np.array(y_test) - np.array(y_pre))\n",
    "# 直接使用 viridis 的色彩映射\n",
    "cmap = plt.get_cmap('viridis')\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "scatter = plt.scatter(y_test, y_pre, c=errors, cmap=cmap, edgecolor='none', s=50, alpha=0.8)\n",
    "\n",
    "# 添加 1:1 参考线\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel('True Values', fontsize=14)\n",
    "plt.ylabel('Predicted Values', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(False)\n",
    "\n",
    "# 显示颜色条\n",
    "cbar = plt.colorbar(scatter, shrink=0.8, pad=0.02)\n",
    "cbar.set_label('Absolute Error', fontsize=12)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "# 计算指标\n",
    "r2 = r2_score(y_test, y_pre)\n",
    "mae = mean_absolute_error(y_test, y_pre)\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pre))\n",
    "plt.text(0.95, 0.05, f'$R^2$ = {r2:.5f}\\nMAE = {mae:.5f}\\nRMSE = {rmse:.5f}', \n",
    "         horizontalalignment='right', verticalalignment='bottom', \n",
    "         transform=plt.gca().transAxes, fontsize=12, \n",
    "         bbox=dict(facecolor='white', alpha=0.8, edgecolor='black', boxstyle='round,pad=0.5'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
